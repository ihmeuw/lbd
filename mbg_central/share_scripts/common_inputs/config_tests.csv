variable,test_call,extra_test1,extra_test2
check_cov_pixelcount,is.flag,"",""
coefs_sum1,is.flag,"if(eval(parse(text = config[V1 == 'coefs_sum1', V2])) == TRUE) { eval(parse(text = config[V1 == 'use_stacking_covs', V2]))  == TRUE } else { TRUE }","if(eval(parse(text = config[V1 == 'coefs_sum1', V2])) == TRUE) { eval(parse(text = config[V1 == 'constrain_children_0_inf', V2]))  == FALSE } else {TRUE}"
constrain_children_0_inf,is.flag,"",""
countries_not_to_rake,is.string,"",""
countries_not_to_subnat_rake,is.string,"",""
ctry_re_prior,is.list,"",""
datatag,is.string,"",""
fit_with_tmb,is.flag,"if(eval(parse(text = config[V1 == 'fit_with_tmb', V2])) == TRUE) { eval(parse(text = config[V1 == 'coefs_sum1', V2]))  == FALSE } else {TRUE}",""
fixed_effects,is.string,"",""
fixed_effects_measures,is.string,"",""
gbd_fixed_effects,is.string,"",""
gbd_fixed_effects_age,is.vector,"",""
gbd_fixed_effects_measures,is.string,"",""
gbm_bf,is.number,"eval(parse(text = config[V1 == 'gbm_bf', V2])) >= 0 ","eval(parse(text = config[V1 == 'gbm_bf', V2])) <= 1"
gbm_lr,is.number,"eval(parse(text = config[V1 == 'gbm_lr', V2])) >= 0 ","eval(parse(text = config[V1 == 'gbm_lr', V2])) <= 1"
gbm_tc,is.number,"eval(parse(text = config[V1 == 'gbm_tc', V2])) > 0",""
ho_mb,is.number,"eval(parse(text = config[V1 == 'ho_mb', V2])) > 0",""
ho_ts,is.number,"eval(parse(text = config[V1 == 'ho_ts', V2])) > 0",""
holdout_strategy,is.string,"",""
indicator_family,"","config[V1 == 'indicator_family', V2] %in% c('gaussian', 'binomial')",""
individual_countries,is.flag,"if(eval(parse(text = config[V1 == 'individual_countries', V2])) == TRUE) eval(parse(text = config[V1 == 'use_inla_country_res', V2]))  == FALSE else TRUE","if(eval(parse(text = config[V1 == 'individual_countries', V2])) == TRUE) eval(parse(text = config[V1 == 'use_inla_country_fes', V2]))  == FALSE else TRUE"
inla_cores,is.number,"eval(parse(text = config[V1 == 'inla_cores', V2])) > 0",""
intercept_prior,is.number,"",""
interval_mo,is.number,"eval(parse(text = config[V1 == 'interval_mo', V2])) == 12",""
intstrat,is.string,"config[V1 == 'intstrat', V2] %in% c('eb', 'ccd', 'grid')",""
jn,is.string,"",""
keep_inla_files,is.flag,"",""
lat_col,is.string,"",""
long_col,is.string,"",""
makeholdouts,is.flag,"",""
memory,is.string,"eval(parse(text = config[V1 == 'memory', V2])) > 0",""
mesh_s_max_edge,is.vector,"eval(parse(text = config[V1 == 'mesh_s_max_edge', V2]))[1] > 0","eval(parse(text = config[V1 == 'mesh_s_max_edge', V2]))[2] > 0"
mesh_s_offset,is.vector,"",""
mesh_t_knots,is.vector,"eval(parse(text = config[V1 == 'mesh_t_knots', V2]))[1] == 1","rev(eval(parse(text = config[V1 == 'mesh_t_knots', V2])))[1] == length(eval(parse(text = config[V1 == 'year_list', V2])))"
metric_space,is.string,"config[V1 == 'metric_space', V2] %in% c('rates', 'counts')",""
modeling_shapefile_version,is.string,"",""
n_ho_folds,is.number,"eval(parse(text = config[V1 == 'n_ho_folds', V2])) > 0",""
n_stack_folds,is.number,"eval(parse(text = config[V1 == 'n_stack_folds', V2])) > 0",""
nugget_prior,is.list,"",""
other_weight,is.string,"",""
pop_measure,is.string,"config[V1 == 'pop_measure', V2] %in% c('a0004m', 'a0004t', 'a65plf', 'a65plm', 'a0514t', 'a1014f', 'a1014m', 'a1519f', 'a1519m', 'a1549m', 'a1549t', 'a2024f', 'a2024m', 'a2529f', 'a2529m')",""
queue,"","",""
rake_countries,is.flag,"",""
rake_transform,is.string,"config[V1 == 'rake_transform', V2] %in% c('none', 'logit')",""
raking_shapefile_version,is.string,"",""
rho_prior,is.list,"",""
run_time,"","",""
s2_mesh_params,is.vector,"sum(eval(parse(text = config[V1 == 's2_mesh_params', V2])) > 0) == 3",""
samples,is.number,"",""
scale_gaussian_variance_N,is.flag,"",""
singularity_version,is.string,"grepl('default|img$', config[V1 == 'singularity_version', V2])",""
skip.inla,"","",""
skip.stacking,"","",""
skipinla,is.flag,"",""
skiptoinla,is.flag,"",""
skiptoinla_from_rundate,is.string,"",""
slots,is.number,"",""
spat_strat,is.string,"config[V1 == 'spat_strat', V2] %in% c('rand', 'poly', 'qt', 'ct')",""
ss_col,is.string,"",""
st_targ,is.number,"",""
stacked_fixed_effects,is.string,"",""
stackers_in_transform_space,is.flag,"",""
subnat_country_to_get,is.string,"",""
subnational_raking,is.flag,"",""
summstats,is.vector,"",""
target_type,is.string,"config[V1 == 'target_type', V2] %in% c('less', 'greater')",""
temp_strat,is.string,"config[V1 == 'temp_strat', V2] %in% c('rand', 'prop', 'prop_comb', 'yr', 'chrono')",""
test,is.flag,"",""
test_pct,is.number,"eval(parse(text = config[V1 == 'test_pct', V2])) >= 0 ","eval(parse(text = config[V1 == 'test_pct', V2])) <= 100"
time_stamp,is.flag,"",""
transform,"","config[V1 == 'transform', V2] %in% c('inverse-logit')",""
use_child_country_fes,is.flag,"if(eval(parse(text = config[V1 == 'individual_countries', V2])) == TRUE) eval(parse(text = config[V1 == 'use_child_country_fes', V2]))  == FALSE else TRUE",""
use_geos_nodes,is.flag,"",""
use_gp,is.flag,"",""
use_inla_country_fes,is.flag,"if(eval(parse(text = config[V1 == 'use_inla_country_fes', V2])) == TRUE) eval(parse(text = config[V1 == 'use_inla_country_res', V2]))  == FALSE else TRUE",""
use_inla_country_res,is.flag,"if(eval(parse(text = config[V1 == 'use_inla_country_res', V2])) == TRUE) eval(parse(text = config[V1 == 'use_inla_country_fes', V2]))  == FALSE else TRUE",""
use_inla_nugget,is.flag,"",""
use_nid_res,is.flag,"",""
use_raw_covs,is.flag,"if(eval(parse(text = config[V1 == 'use_raw_covs', V2])) == TRUE) eval(parse(text = config[V1 == 'coefs_sum1', V2]))  == FALSE else TRUE",""
use_s2_mesh,is.flag,"",""
use_share,is.flag,"",""
use_stacking_covs,is.flag,"",""
use_subnat_res,is.flag,"if(eval(parse(text = config[V1 == 'use_subnat_res', V2])) == TRUE) { (eval(parse(text = config[V1 == 'use_inla_country_fes', V2]))  == TRUE) | (eval(parse(text = config[V1 == 'use_inla_country_res', V2]))  == TRUE) } else TRUE",""
withtag,is.flag,"",""
year_list,is.vector,"",""
yearload,is.string,"config[V1 == 'yearload', V2] %in% c('annual')",""
yr_col,is.string,"",""
z_list,is.vector,"",""
zcol,is.string,"",""
